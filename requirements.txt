Pillow
einops
safetensors
timm
tomesd
torch>=2.1.2
torchdiffeq
torchsde
decord
datasets
numpy
scikit-image
opencv-python
omegaconf
SentencePiece
albumentations
imageio[ffmpeg]
imageio[pyav]
tensorboard
beautifulsoup4
ftfy
func_timeout
accelerate>=0.25.0
gradio>=3.41.2,<=3.48.0
diffusers>=0.30.1,<=0.31.0
transformers>=4.46.2
pycocotools
xfuser[diffusers,flash-attn]==0.4.0
yunchang==0.4.1
flash_attn==2.6.3
# install flash attention 3 from https://github.com/Dao-AILab/flash-attention.git
neptune